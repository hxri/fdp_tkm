{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample action: 0\n",
      "observation space shape: (8,)\n",
      "sample observation: [-1.4291949   1.1851361  -0.30540586 -0.2943617   0.65500134 -0.17984001\n",
      "  1.5782881   1.2899084 ]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('LunarLander-v2')  # continuous: LunarLanderContinuous-v2\n",
    "\n",
    "# required before you can step the environment\n",
    "env.reset()\n",
    "\n",
    "# sample action:\n",
    "print(\"sample action:\", env.action_space.sample())\n",
    "\n",
    "# observation space shape:\n",
    "print(\"observation space shape:\", env.observation_space.shape)\n",
    "\n",
    "# sample observation:\n",
    "print(\"sample observation:\", env.observation_space.sample())\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env: The environment\n",
    "# \ts (list): The state. Attributes:\n",
    "# \t\t\t\ts[0] is the horizontal coordinate\n",
    "# \t\t\t\ts[1] is the vertical coordinate\n",
    "# \t\t\t\ts[2] is the horizontal speed\n",
    "# \t\t\t\ts[3] is the vertical speed\n",
    "# \t\t\t\ts[4] is the angle\n",
    "# \t\t\t\ts[5] is the angular speed\n",
    "# \t\t\t\ts[6] 1 if first leg has contact, else 0\n",
    "# \t\t\t\ts[7] 1 if second leg has contact, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "env = gym.make('LunarLander-v2')  # continuous: LunarLanderContinuous-v2\n",
    "env.reset()\n",
    "\n",
    "for step in range(200):\n",
    "\tenv.render()\n",
    "\t# take random action\n",
    "\tenv.step(env.action_space.sample())\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n",
      "-100 True\n"
     ]
    }
   ],
   "source": [
    "for step in range(200):\n",
    "\tenv.render()\n",
    "\t# take random action\n",
    "\tobs, reward, done, info = env.step(env.action_space.sample())\n",
    "\tprint(reward, done)\n",
    "\n",
    "env.close()\n",
    "\n",
    "# -100s and True for the environment being done mean the lander has crashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | -372     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1165     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.0103   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -17      |\n",
      "|    value_loss         | 262      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.4     |\n",
      "|    ep_rew_mean        | -347     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1240     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0.0298   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -3.09    |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 103       |\n",
      "|    ep_rew_mean        | -314      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1262      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28     |\n",
      "|    explained_variance | -3.86e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -9.39     |\n",
      "|    value_loss         | 166       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 123      |\n",
      "|    ep_rew_mean        | -385     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1222     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | -0.00386 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 2.05     |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 125      |\n",
      "|    ep_rew_mean        | -383     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1226     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -0.0199  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 5.09     |\n",
      "|    value_loss         | 36.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 135       |\n",
      "|    ep_rew_mean        | -383      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1225      |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.01     |\n",
      "|    explained_variance | -0.000702 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.51      |\n",
      "|    value_loss         | 18.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 138       |\n",
      "|    ep_rew_mean        | -360      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1232      |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.928    |\n",
      "|    explained_variance | -0.000288 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 0.358     |\n",
      "|    value_loss         | 4.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -349     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1225     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | -0.00422 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -15.6    |\n",
      "|    value_loss         | 95.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 142       |\n",
      "|    ep_rew_mean        | -322      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1225      |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.909    |\n",
      "|    explained_variance | -7.39e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -12.3     |\n",
      "|    value_loss         | 50.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 146       |\n",
      "|    ep_rew_mean        | -312      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1226      |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.771    |\n",
      "|    explained_variance | -0.000195 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 4.21      |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -301     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1220     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.189    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -5.2     |\n",
      "|    value_loss         | 102      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -301     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1153     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.25     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 21.5     |\n",
      "|    value_loss         | 288      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | -286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1133     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | -0.00735 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -15.7    |\n",
      "|    value_loss         | 183      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | -277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1138     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.741   |\n",
      "|    explained_variance | -0.147   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 7.21     |\n",
      "|    value_loss         | 188      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 178      |\n",
      "|    ep_rew_mean        | -272     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1141     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.752   |\n",
      "|    explained_variance | -0.00374 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 180      |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1147     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.731   |\n",
      "|    explained_variance | -0.00855 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 6.47     |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 179       |\n",
      "|    ep_rew_mean        | -258      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1154      |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.07     |\n",
      "|    explained_variance | -0.000445 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -4.59     |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 182      |\n",
      "|    ep_rew_mean        | -252     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1152     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.351   |\n",
      "|    explained_variance | -0.0237  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 182      |\n",
      "|    ep_rew_mean        | -239     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1158     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.796   |\n",
      "|    explained_variance | -0.0225  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 3.37     |\n",
      "|    value_loss         | 8.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -234     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1164     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.00847  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.3     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "0.8209626145695961\n",
      "0.6823537305028833\n",
      "1.0850716809247853\n",
      "1.2662981451163955\n",
      "1.355947563491527\n",
      "1.7729512072728835\n",
      "2.027366757868664\n",
      "2.1409856730583683\n",
      "0.24337093655214062\n",
      "-0.09307851095107253\n",
      "-0.5129766503737858\n",
      "-0.6129894837251573\n",
      "-0.9741773604065702\n",
      "-1.2840292015151238\n",
      "-1.1634240796817028\n",
      "-1.5225367719447422\n",
      "-2.1471184334823463\n",
      "-2.2959567830149568\n",
      "-2.541562023584133\n",
      "-2.829791891326009\n",
      "-3.1740576443228563\n",
      "-0.6560149420956691\n",
      "-1.2265488834404608\n",
      "-3.6586051590217594\n",
      "1.3143233576042064\n",
      "-0.6492893135087627\n",
      "0.4272423294532473\n",
      "-0.6390983560546488\n",
      "-1.8083719105820137\n",
      "-1.363744335648238\n",
      "-1.2574843831726128\n",
      "0.9595003637366346\n",
      "1.3471214500083135\n",
      "-5.175647061222974\n",
      "-2.4811635453607606\n",
      "-3.518334840089426\n",
      "-4.783259275825059\n",
      "-4.303574541501972\n",
      "-4.051355897883439\n",
      "-3.8172578892219335\n",
      "-3.6010687161650865\n",
      "-3.178685672999079\n",
      "-2.8478002863962204\n",
      "-1.849231037235245\n",
      "-2.60534545590579\n",
      "-2.3550434431787424\n",
      "-2.1002535200626355\n",
      "0.28554253910176614\n",
      "-1.268048996817231\n",
      "-1.435608669898811\n",
      "-1.0832539181797347\n",
      "-0.9921016871655002\n",
      "-0.22570367608050218\n",
      "-0.5866418859525016\n",
      "-0.21449620369682407\n",
      "-1.3383376451957247\n",
      "0.16319984497769838\n",
      "0.3252826486223921\n",
      "-0.3106301490666283\n",
      "0.7366994048843207\n",
      "0.9119450910628484\n",
      "1.19435248480258\n",
      "1.9382772842555596\n",
      "1.9151023828369602\n",
      "1.5322114450280264\n",
      "1.946197578829101\n",
      "2.576990587350065\n",
      "2.249509651527956\n",
      "1.6839949828801763\n",
      "1.3997282564086617\n",
      "2.0833390174118747\n",
      "2.1635904033005047\n",
      "2.325472305812441\n",
      "3.5968795361076333\n",
      "3.246998623245571\n",
      "2.961008808822652\n",
      "2.7677538855340074\n",
      "2.875086674757381\n",
      "2.412923924570589\n",
      "2.824667706820095\n",
      "1.7484547714306984\n",
      "3.150042504141824\n",
      "2.486933854862042\n",
      "3.6571946751435873\n",
      "4.915968189817829\n",
      "2.4282197983517166\n",
      "4.055246415131593\n",
      "4.927273084936741\n",
      "4.12123403196668\n",
      "5.588715914871284\n",
      "5.637306836184377\n",
      "5.471809088061787\n",
      "3.58090321738801\n",
      "5.668563299103693\n",
      "6.186830798458158\n",
      "4.656679385535097\n",
      "3.6434106493364142\n",
      "0.4961486938179121\n",
      "-2.251659804343336\n",
      "0.2242740047362986\n",
      "-3.415213754005633\n",
      "-3.559220484027007\n",
      "-0.35223671635104664\n",
      "-0.3419024026363388\n",
      "-3.8374605693163333\n",
      "-0.09295536197128057\n",
      "2.339391279653012\n",
      "-0.30023077642819657\n",
      "-2.1968512351828506\n",
      "-2.1218775444498474\n",
      "0.30067096585328273\n",
      "3.382633099767543\n",
      "-0.005884653909578208\n",
      "-1.4875083381431182\n",
      "1.1335985060103553\n",
      "0.9208521395441778\n",
      "-0.6043647074084675\n",
      "-0.17177012718404966\n",
      "-2.7034022742652892\n",
      "-5.06845627066346\n",
      "1.8353741971757926\n",
      "0.22992994063436073\n",
      "-2.4238859107997994\n",
      "-3.78651783690687\n",
      "-4.71740974185468\n",
      "-3.9819552001868486\n",
      "-4.019095170089854\n",
      "-3.9240301513647737\n",
      "-3.545655383967953\n",
      "-3.462603907491483\n",
      "-3.282077403974482\n",
      "-2.7009259865034765\n",
      "-2.411110555763996\n",
      "-3.306188222063315\n",
      "-2.2570819519115433\n",
      "-1.8670741029091562\n",
      "-1.6365309395809493\n",
      "-1.2276904191884899\n",
      "-1.2956935938423715\n",
      "-1.8363607446137735\n",
      "-0.773881687612543\n",
      "-2.263733435093701\n",
      "-0.6666354780162453\n",
      "-0.6995922512238326\n",
      "9.809555636076228\n",
      "0.03883035788723646\n",
      "-0.8649249685662699\n",
      "11.187075707793015\n",
      "-6.52007429470754\n",
      "-14.16698766427609\n",
      "-16.73449681946684\n",
      "-100\n",
      "1.2251885057677725\n",
      "1.0224847503571197\n",
      "-1.599723837796364\n",
      "-0.07568999504148904\n",
      "-1.086369112437427\n",
      "-0.5167948438209635\n",
      "0.2910741366743366\n",
      "1.209241518979128\n",
      "1.1123960107572952\n",
      "1.081968956293225\n",
      "1.2220504587466336\n",
      "-0.247175359760422\n",
      "-1.9092448294574809\n",
      "-0.11337594381308122\n",
      "-0.553990766918605\n",
      "-1.418806853728529\n",
      "-0.23524289019809316\n",
      "-1.0311234479692348\n",
      "-2.210456548646948\n",
      "0.7270926519603449\n",
      "-1.7647281336282106\n",
      "0.42503268525525756\n",
      "-1.4157431406541423\n",
      "-1.9874805795224961\n",
      "-2.7738210318404968\n",
      "-3.1557070709129946\n",
      "-0.9019215741394249\n",
      "0.5344703971907563\n",
      "0.9943184230352642\n",
      "2.1874007575931502\n",
      "-1.771443597889106\n",
      "0.2533186461417188\n",
      "0.6981965476712275\n",
      "-3.241838342154493\n",
      "-2.1416171239546484\n",
      "-3.22503181881176\n",
      "-0.36281316406555564\n",
      "-1.0744213374236995\n",
      "-1.9570137811647033\n",
      "-2.400458176972363\n",
      "-2.2270882152976967\n",
      "-0.524385297580426\n",
      "-1.8631446442201696\n",
      "-0.6327598463986022\n",
      "-1.0602688677687968\n",
      "-0.29992712456156595\n",
      "-0.6396694307233293\n",
      "-1.5316222610331807\n",
      "-0.2589837668903374\n",
      "-0.5162232509910496\n",
      "-0.9735285833177898\n",
      "-2.5367604916407513\n",
      "-0.22819190317002835\n",
      "-3.264486753250213\n",
      "0.8773439849572366\n",
      "-1.078910886760741\n",
      "1.126622244259637\n",
      "1.0705763269839406\n",
      "1.0418971112701183\n",
      "-0.8064005238213554\n",
      "1.5716435087726108\n",
      "0.678564631889327\n",
      "1.4890731283695982\n",
      "1.817606997005215\n",
      "1.5422838321333938\n",
      "1.5915976152801192\n",
      "1.771825028693969\n",
      "2.7377421811341778\n",
      "1.913473540254597\n",
      "1.6302616710819222\n",
      "0.29651473414672297\n",
      "2.1006770315596954\n",
      "3.3051666350691677\n",
      "4.0738322959674464\n",
      "2.0925115124749256\n",
      "1.3621590468462272\n",
      "2.7184629348418925\n",
      "-3.1450920012298296\n",
      "-0.05001649012321535\n",
      "-0.9753820630627843\n",
      "-1.5505553504029763\n",
      "0.3519437811850821\n",
      "0.1299401075257663\n",
      "-2.1127075222746896\n",
      "-2.390923279278371\n",
      "-1.4557806734334224\n",
      "0.00358181759947912\n",
      "1.9098054853935877\n",
      "-1.962498491646602\n",
      "-0.36596457119977116\n",
      "-0.3750956367655817\n",
      "-2.466343267169576\n",
      "-2.1544548013737197\n",
      "-1.682796046725673\n",
      "-1.5057263842413875\n",
      "-1.0591139105509615\n",
      "-1.4385444812123456\n",
      "-0.7237414781139819\n",
      "-0.8962889514260326\n",
      "-3.0830625653208186\n",
      "-3.850246025616644\n",
      "0.4162399826756211\n",
      "0.6062030425488569\n",
      "-0.7310195610990207\n",
      "0.7622412422746845\n",
      "0.1791550348061162\n",
      "-0.8542157064481717\n",
      "0.4139031328838996\n",
      "1.74745412632343\n",
      "-1.2952207010984\n",
      "-2.5607364526078684\n",
      "-2.3075905032268893\n",
      "-1.9638566354840055\n",
      "2.0834610265236053\n",
      "0.36456635154634115\n",
      "-0.6947891935719099\n",
      "-3.7767119565345295\n",
      "0.7686169885860477\n",
      "0.7902464042591373\n",
      "-1.4480368046432261\n",
      "-0.18492640348989653\n",
      "0.4626687695263183\n",
      "0.616677176591794\n",
      "0.6095027083699278\n",
      "0.9848118532428896\n",
      "0.9719888938954011\n",
      "-0.06996549896692272\n",
      "0.8137033019281443\n",
      "0.7406061069878842\n",
      "0.9670528366038422\n",
      "0.956337854601345\n",
      "4.429911930042761\n",
      "5.526013929058348\n",
      "4.141169591606041\n",
      "3.3272083508308414\n",
      "2.772395041046434\n",
      "2.508650736143051\n",
      "1.6529160944511443\n",
      "1.9137603638377538\n",
      "3.1520121540788013\n",
      "2.8945755168123926\n",
      "3.901856439005809\n",
      "-0.5949589037785745\n",
      "-1.4277023666408468\n",
      "-0.20251624122331008\n",
      "-3.7219247708714804\n",
      "1.0012827275407516\n",
      "-0.3472317238430264\n",
      "-2.6959851176047662\n",
      "-4.95555041487708\n",
      "-0.9168665818516388\n",
      "1.612770871534235\n",
      "-1.8936706774846812\n",
      "-1.8757788017780854\n",
      "-5.167577238620395\n",
      "-1.18762791464643\n",
      "-4.579847426157914\n",
      "-4.734371310717165\n",
      "-3.8913678185938623\n",
      "-2.1925184428769624\n",
      "-4.678672234482093\n",
      "-3.836741819907472\n",
      "-3.786280376806245\n",
      "-2.750727997001138\n",
      "-3.245121284739041\n",
      "-2.2066582611874024\n",
      "-3.471742439448394\n",
      "-2.2398009392100264\n",
      "-3.7754550475277595\n",
      "-3.249637319842253\n",
      "-1.4436746155319315\n",
      "-1.512461682629065\n",
      "-1.1436919239988572\n",
      "-1.011516375209992\n",
      "-0.8094207795309092\n",
      "-1.0263088276383587\n",
      "-0.6854108297370931\n",
      "-0.49473885777442095\n",
      "-0.17723036492776487\n",
      "-0.18306828897257674\n",
      "0.006404351254930135\n",
      "0.3793979726272994\n",
      "0.4835315365126587\n",
      "0.5619162428409947\n",
      "0.954841836693846\n",
      "1.152471846561981\n",
      "1.2268310158186477\n",
      "2.872737998024843\n",
      "2.824474070860316\n",
      "1.9230096867144948\n",
      "0.8213562832775778\n",
      "2.1606241999440683\n",
      "3.7954034614764796\n",
      "2.1526739166262714\n",
      "4.470784485531067\n",
      "3.33137767818219\n",
      "2.464228099572961\n",
      "2.6795736620066295\n",
      "2.5913775813832856\n",
      "3.356726930289665\n",
      "2.6867839717639415\n",
      "5.246503588895462\n",
      "2.9637655970998664\n",
      "4.287915188538688\n",
      "6.093451127742225\n",
      "3.4774712275103754\n",
      "4.278945896388092\n",
      "6.013581098994149\n",
      "-0.014781385880257847\n",
      "-1.523130093744544\n",
      "-3.6454583147317963\n",
      "-1.542187840155026\n",
      "-1.0456900420313275\n",
      "1.114502486019444\n",
      "-2.00044437238937\n",
      "0.020106446664169664\n",
      "-0.6388793754146207\n",
      "-0.09538253637463184\n",
      "-1.3000557146508698\n",
      "0.9591550532260669\n",
      "-0.9027749544855681\n",
      "0.08728965450926013\n",
      "0.7704805592788488\n",
      "0.5505936302676673\n",
      "2.61840551833252\n",
      "-0.7429039985015493\n",
      "-2.8230302478910856\n",
      "1.710918861717755\n",
      "-5.324576511131311\n",
      "-4.991929720387673\n",
      "-2.3402552729859165\n",
      "-3.744404518014987\n",
      "-3.9530454199764606\n",
      "-4.5241084464498895\n",
      "-3.4372475800860216\n",
      "-3.4334671349285473\n",
      "-3.878048875845667\n",
      "-3.0491374710175863\n",
      "-2.8311719390622714\n",
      "-2.473896202948508\n",
      "-2.254402345732926\n",
      "-2.1261765322397523\n",
      "-2.860434251297721\n",
      "-1.337687322681602\n",
      "-1.4330657309941148\n",
      "-1.1917613241503762\n",
      "-0.8405167312328945\n",
      "-0.6575314156061427\n",
      "-1.4057517930281904\n",
      "-0.3312406126389351\n",
      "-1.0329046136135844\n",
      "0.07445763697148891\n",
      "-2.233698703677123\n",
      "0.9481252065139654\n",
      "0.8628112649404056\n",
      "-1.3656303158000924\n",
      "1.4801612066483767\n",
      "1.5420128125793167\n",
      "-0.5151774564758853\n",
      "2.230100477470445\n",
      "2.278552905031917\n",
      "2.607897291173829\n",
      "1.8818799311815553\n",
      "2.0510247204227428\n",
      "2.7631002792756205\n",
      "2.872102778237975\n",
      "2.167922663438657\n",
      "3.217956339872417\n",
      "3.5923021206102717\n",
      "3.8788857326737527\n",
      "3.6959567436833654\n",
      "4.169751449290147\n",
      "4.383827198224936\n",
      "4.71626447047703\n",
      "5.129269194113033\n",
      "5.844270544970596\n",
      "4.832715295379928\n",
      "7.637147604003329\n",
      "6.57587781719698\n",
      "5.749538474385145\n",
      "7.0956702331112185\n",
      "-1.0463835317944217\n",
      "-4.646229747836684\n",
      "-4.712167658624408\n",
      "-1.8869543954758854\n",
      "-2.1614360669006656\n",
      "-5.225956037494043\n",
      "-1.4820936635715356\n",
      "11.359980452198169\n",
      "6.309780989359067\n",
      "6.597133625081281\n",
      "7.441129736173477\n",
      "1.0108681150510535\n",
      "-100\n",
      "-0.07726733428046259\n",
      "-0.07537412800581819\n",
      "0.7782171669227409\n",
      "1.9173813308788794\n",
      "0.2773973137520159\n",
      "1.2196580800394485\n",
      "0.38853585793555223\n",
      "0.5325710052602244\n",
      "0.6256123729900025\n",
      "2.02103556491262\n",
      "-0.32074666754817716\n",
      "-0.7758075320830631\n",
      "0.49295664873993134\n",
      "0.4624785644154031\n",
      "0.147352238339505\n",
      "-0.7619742596792094\n",
      "0.019097265563318616\n",
      "0.518501285665036\n",
      "-0.5094768117141928\n",
      "-0.6475868431114964\n",
      "-1.5188821723932893\n",
      "-2.377087831631144\n",
      "-1.914989675321549\n",
      "-0.747996056837269\n",
      "1.3144715708193473\n",
      "1.4987909329900446\n",
      "1.4815607811639893\n",
      "-2.2799078902487495\n",
      "1.2109373691442442\n",
      "0.6098913195887234\n",
      "-0.7172261856911064\n",
      "0.04666034593297469\n",
      "-3.8558151969459957\n",
      "2.210314363280628\n",
      "-3.714440137544898\n",
      "-3.5134909431118317\n",
      "-3.2784167647561717\n",
      "1.5299870613637097\n",
      "2.2923114107653477\n",
      "-2.8523198960503735\n",
      "-0.574536099168131\n",
      "-1.977002949319416\n",
      "-2.016048094146383\n",
      "-0.231483400961298\n",
      "-1.3172990932891253\n",
      "-0.4537400534177493\n",
      "-2.0043210252509764\n",
      "-0.7940594654079962\n",
      "-1.0294349264269147\n",
      "-0.7979688639753408\n",
      "1.0695141614105068\n",
      "0.06406546041544631\n",
      "-0.32755565206300047\n",
      "-0.2983553135809689\n",
      "0.27598521677769555\n",
      "-2.5914546026397316\n",
      "-1.8294175156216455\n",
      "-2.76947318851727\n",
      "0.6562581548088542\n",
      "-2.6734008398232048\n",
      "1.007354599765365\n",
      "-1.429571403582844\n",
      "1.2710116739748696\n",
      "1.5080545959955896\n",
      "1.1095268968774519\n",
      "1.6221768932712746\n",
      "1.544084707796402\n",
      "-0.4096617428347031\n",
      "0.8870546918093509\n",
      "2.0374785931995247\n",
      "1.5703332288977492\n",
      "0.22304252092713456\n",
      "0.11956151188591663\n",
      "2.599750297958424\n",
      "2.364298954319311\n",
      "1.8352378685757855\n",
      "3.50429714889155\n",
      "2.1528991085278166\n",
      "0.5019794788071692\n",
      "3.2889848067335676\n",
      "0.591032201731349\n",
      "-1.8539170006040024\n",
      "-1.7753429504891642\n",
      "-0.864244351768565\n",
      "-4.051513788197997\n",
      "-1.2617171143964925\n",
      "-0.7898374765549534\n",
      "-1.0568828572679536\n",
      "-2.031317266208788\n",
      "-2.197117726887967\n",
      "-0.576799769848708\n",
      "-2.224226396498966\n",
      "-1.8772350362307009\n",
      "-1.2200977310963481\n",
      "-0.9690642925460111\n",
      "-2.2392036673453206\n",
      "-2.3456934232306126\n",
      "0.09576006016972088\n",
      "-1.6406000266604963\n",
      "-1.8355857413403942\n",
      "-1.7932367457586327\n",
      "-0.5779418699291228\n",
      "0.8363581141418706\n",
      "-0.2501963736989296\n",
      "0.099686577866579\n",
      "-0.20646439638502898\n",
      "-0.40385979539931216\n",
      "-0.5368868257163786\n",
      "-0.9481998925622281\n",
      "4.372394674079101\n",
      "-0.5937566448322105\n",
      "-1.461567761640082\n",
      "-1.6865419530792554\n",
      "0.41253443921000327\n",
      "-1.7984800515653194\n",
      "3.2425576745334412\n",
      "-1.5886070278017417\n",
      "3.5521260048791534\n",
      "1.4218340045715194\n",
      "-0.8454726601792959\n",
      "-0.9867072132269346\n",
      "-0.8391170799399947\n",
      "2.8873352177787526\n",
      "-0.7174191921112538\n",
      "0.4511166828380919\n",
      "0.10449682804727559\n",
      "-0.48793241141834187\n",
      "1.3572010334229219\n",
      "0.2448268105693228\n",
      "0.33872470516294695\n",
      "0.5239011882364093\n",
      "0.5660700107438867\n",
      "4.033631702172596\n",
      "2.699530775789225\n",
      "1.140137566693711\n",
      "3.9564659575081125\n",
      "1.4374807646831596\n",
      "2.5269618650675456\n",
      "4.19728775971073\n",
      "3.224722005624426\n",
      "2.1191572820136186\n",
      "6.255858368942239\n",
      "3.095270362619698\n",
      "4.73039042972415\n",
      "-1.5873261875767344\n",
      "-4.615519554247498\n",
      "-0.6240469777863382\n",
      "0.3501215850813935\n",
      "-4.556317806977545\n",
      "-2.5710512383930846\n",
      "-5.199634800997699\n",
      "-3.7347261225414057\n",
      "-1.606603717092969\n",
      "-0.6740208595193906\n",
      "-1.1728511494464613\n",
      "-6.129900148182485\n",
      "-3.4917148897181276\n",
      "-5.782541297624305\n",
      "-0.9437349369793708\n",
      "-5.494968281256404\n",
      "-0.8939716528732504\n",
      "-5.253269995096644\n",
      "-3.2510295491296004\n",
      "-4.723107479787159\n",
      "-4.670100497354354\n",
      "-4.368836004125511\n",
      "-4.077785109539746\n",
      "-3.848672496157404\n",
      "-3.531214305329114\n",
      "-1.3698947243107\n",
      "-3.2064848884699857\n",
      "-2.88795134751649\n",
      "-2.7949344854029037\n",
      "-2.4548104683831853\n",
      "0.34901070701057507\n",
      "-1.9160725294419183\n",
      "-1.8810855884556463\n",
      "-1.7129116112585325\n",
      "-1.1856601199987142\n",
      "-0.9800089748229357\n",
      "-0.7284344022918947\n",
      "-0.47474842552327234\n",
      "-0.3092266511335129\n",
      "0.07498699681573953\n",
      "1.5537825272626378\n",
      "0.27442385352355925\n",
      "0.5800863139087096\n",
      "0.9489931862142964\n",
      "3.2819905797058313\n",
      "1.5587111306280519\n",
      "1.315642301288791\n",
      "1.7652795345973515\n",
      "2.875835944171212\n",
      "1.4818457232484559\n",
      "1.8424574547690906\n",
      "1.6042758104264407\n",
      "3.1068292541166445\n",
      "0.9998387270201021\n",
      "1.3481011254572308\n",
      "2.5051104413019813\n",
      "2.8869292080412676\n",
      "2.9886111394726926\n",
      "2.0125213295706885\n",
      "2.3537890691961936\n",
      "3.7308606110590974\n",
      "2.608214770829318\n",
      "3.334074507254809\n",
      "3.307899931562088\n",
      "2.72127462669543\n",
      "2.26611706492933\n",
      "3.3968042743224602\n",
      "3.259512014976481\n",
      "3.2740043919591257\n",
      "4.935945966179458\n",
      "3.601547308523732\n",
      "4.408702775231018\n",
      "3.676700498346635\n",
      "3.988921518880319\n",
      "5.137592406245443\n",
      "3.9101885253308355\n",
      "-0.30386534040057994\n",
      "-1.7707250689881733\n",
      "-4.039748811730475\n",
      "0.835800857241378\n",
      "-1.1771476922886166\n",
      "-3.4571203928563987\n",
      "-2.3307187812485095\n",
      "-3.825468631848497\n",
      "-3.576584204618899\n",
      "-3.697754115734898\n",
      "-2.808678175621327\n",
      "-2.6767384051217276\n",
      "-0.8046359481671062\n",
      "0.10400236602530982\n",
      "-5.850382983440539\n",
      "-1.4010068657876673\n",
      "0.16804155464664633\n",
      "0.1388117019228446\n",
      "-3.429533075786355\n",
      "-6.1108866610426835\n",
      "-1.9973926928462504\n",
      "-0.8512076508204587\n",
      "0.19235697094323428\n",
      "-3.9767378278127863\n",
      "-2.1514427080109497\n",
      "-3.741589436401955\n",
      "-5.873892901540443\n",
      "-3.77488488715436\n",
      "-4.467895430022895\n",
      "-5.382315627656907\n",
      "-5.2513881470781305\n",
      "5.11074443246028\n",
      "13.845225939939697\n",
      "-6.462102917052703\n",
      "-10.033457275051346\n",
      "-19.974427659022723\n",
      "-9.821070521077983\n",
      "-9.500854022210858\n",
      "-12.736804574847657\n",
      "-9.130253562102181\n",
      "-8.940537167141228\n",
      "-8.752787963547545\n",
      "-100\n",
      "1.0209220303577637\n",
      "-1.1548915980026766\n",
      "-1.0718296387420583\n",
      "2.867130366462942\n",
      "1.2727431734218555\n",
      "0.014077763272422328\n",
      "1.277764133013602\n",
      "-0.25595206824830824\n",
      "1.9995575019764658\n",
      "2.0791333131559613\n",
      "0.9805235924792839\n",
      "0.9703033311744036\n",
      "3.2331653261634132\n",
      "-0.42136944346227095\n",
      "2.525918194831246\n",
      "0.07894529858786542\n",
      "2.9031264793014886\n",
      "1.8135962711348952\n",
      "0.828974902760035\n",
      "-1.3738493976311463\n",
      "2.063539577117166\n",
      "0.3110652706348674\n",
      "-2.114082798201082\n",
      "2.989198383382228\n",
      "-1.7243047950784092\n",
      "0.2657109978639312\n",
      "1.6684928180304268\n",
      "3.060304390203993\n",
      "-2.8833698327324826\n",
      "1.4968910804946745\n",
      "-1.7790859164966821\n",
      "-2.327092093068272\n",
      "-2.8613109398569905\n",
      "0.3665589921247488\n",
      "1.995267485307562\n",
      "2.4686163570691066\n",
      "0.16765089234716585\n",
      "1.1994649862019002\n",
      "-3.680153065385325\n",
      "3.1745427692937485\n",
      "-0.9635827285910239\n",
      "-1.6736003940542605\n",
      "-2.9278180718515032\n",
      "-3.1342022195090067\n",
      "-3.471208373392868\n",
      "0.12430477754231789\n",
      "-2.686003648146992\n",
      "1.1393079864354945\n",
      "-2.674704731061921\n",
      "-2.430167988290974\n",
      "3.353874406835968\n",
      "1.5999251254016655\n",
      "-1.8361444296938305\n",
      "-3.2825231960627534\n",
      "-2.0520060960527915\n",
      "0.5362495536034657\n",
      "-1.0987541843556403\n",
      "-0.45187319906587503\n",
      "1.2683335803184945\n",
      "0.3665652363182062\n",
      "-1.2303051466318948\n",
      "0.08202418806098535\n",
      "-0.09333567404323048\n",
      "1.1245523623081624\n",
      "0.374541148536548\n",
      "0.4802004281526149\n",
      "0.018700899169347168\n",
      "-1.8615982713303925\n",
      "1.273549285434666\n",
      "-0.26123674896541504\n",
      "-0.3068243740474543\n",
      "-0.002857994482030779\n",
      "0.2535097349723696\n",
      "0.15871156790442\n",
      "0.7995668756602583\n",
      "0.24563279879513972\n",
      "-0.46957427363303167\n",
      "0.3159732303613339\n",
      "0.6681913445513998\n",
      "1.209704341455432\n",
      "0.3230878346617317\n",
      "2.0351044306779342\n",
      "2.008627415545392\n",
      "0.7239144322342213\n",
      "0.17642961506394955\n",
      "2.5048502494099423\n",
      "0.4363189875248111\n",
      "1.3737483110213986\n",
      "1.1619380392120433\n",
      "2.737794938101105\n",
      "1.8411397702224803\n",
      "2.9653135557982764\n",
      "-2.3297210534359065\n",
      "-2.7049905859674537\n",
      "-1.1240564816062022\n",
      "-2.6716564091026553\n",
      "-2.5360548819323183\n",
      "-1.1334753247937772\n",
      "-1.1306977974970949\n",
      "-3.2094743185326307\n",
      "-3.0058020281391746\n",
      "-1.1914497999612184\n",
      "-0.7848115932767314\n",
      "-2.992096298968778\n",
      "-0.6732367583678343\n",
      "-1.991412665860679\n",
      "-1.7247737666465526\n",
      "-3.1078361697941146\n",
      "-1.547565314148801\n",
      "-3.741310196173589\n",
      "-1.4298936552008559\n",
      "-3.5790407486513116\n",
      "-3.1887379768939352\n",
      "-1.115942029788356\n",
      "-1.7212348475037687\n",
      "-5.196244201649949\n",
      "-0.11138580581953647\n",
      "0.04321141436776202\n",
      "0.42476348537550734\n",
      "0.10844400079270258\n",
      "-3.8865062811138373\n",
      "-3.7704623508725477\n",
      "-3.5877103821916294\n",
      "-1.5832892301763934\n",
      "-2.7513758247528117\n",
      "-2.5472155921056285\n",
      "-2.4301027634033674\n",
      "-0.7113279974732507\n",
      "-2.1496244813136784\n",
      "-1.6824992046118712\n",
      "-0.4410905075234723\n",
      "-2.9651463120104777\n",
      "-3.5088455525775997\n",
      "-2.742918283785417\n",
      "-0.15361547730577627\n",
      "-0.33732025106607355\n",
      "-0.18813056157136884\n",
      "-0.05170207680836711\n",
      "0.28863344259758716\n",
      "-0.23935513797262614\n",
      "0.6401712873224039\n",
      "0.9019958505892884\n",
      "1.1025737679636916\n",
      "1.2612096400965538\n",
      "1.6183575779648447\n",
      "1.5627327288864887\n",
      "2.024514229089563\n",
      "1.942463169156299\n",
      "2.8940256225717294\n",
      "4.048340587014576\n",
      "3.4777167883821223\n",
      "3.6533228251172263\n",
      "2.472522978972792\n",
      "3.6349022555128956\n",
      "2.8823705137003346\n",
      "3.159709604842658\n",
      "1.9772893457209875\n",
      "2.0416638070964668\n",
      "2.8856200675226673\n",
      "3.5792720778142213\n",
      "2.7534398664105324\n",
      "3.6538846772194633\n",
      "6.142797135581202\n",
      "2.838792525989534\n",
      "3.196514360743238\n",
      "5.636068285619825\n",
      "0.7619682582135863\n",
      "-4.688580492332107\n",
      "-1.6986176522264202\n",
      "-1.2919772468931285\n",
      "-1.664808441709215\n",
      "-0.641358401669794\n",
      "-5.040704970653592\n",
      "-2.363172532870254\n",
      "-5.466981016273961\n",
      "1.2924404874718618\n",
      "-2.6618990496549086\n",
      "-2.454291674373269\n",
      "-1.3481779526317041\n",
      "-1.1362572209455266\n",
      "-2.52646165873104\n",
      "-3.1270529494659796\n",
      "-5.722097021147049\n",
      "-5.466346821092684\n",
      "-3.2566845287255886\n",
      "-4.9817429689042845\n",
      "-1.9642816673468133\n",
      "-4.695718946105074\n",
      "-4.5316933892956675\n",
      "-4.192442025573\n",
      "-3.677505774249225\n",
      "-3.4693911620485935\n",
      "-2.069655049784717\n",
      "-3.364913305468433\n",
      "-2.893412270842616\n",
      "-2.667851627477232\n",
      "-2.5032320141461626\n",
      "-2.2012438821154476\n",
      "-1.8829960786146092\n",
      "-1.667342530962087\n",
      "-1.451681930721178\n",
      "0.25681966206586254\n",
      "-0.9629117108851506\n",
      "-0.7227259309054819\n",
      "-0.4313049360947889\n",
      "-0.3608881564857984\n",
      "-0.0035553478963652185\n",
      "0.3347737525681407\n",
      "0.8035731169694611\n",
      "1.1664392989966939\n",
      "1.3775895784141892\n",
      "1.39337593513912\n",
      "2.011744449213468\n",
      "2.1303308769583795\n",
      "2.428773157305767\n",
      "2.3816364399439296\n",
      "2.3257142491061997\n",
      "1.2024663422639719\n",
      "0.7361311255300051\n",
      "79.63180965583635\n",
      "-6.394801814188496\n",
      "-4.047700731723409\n",
      "-12.816417922742827\n",
      "-3.378283598569537\n",
      "-3.281664219565839\n",
      "-2.9192831870564917\n",
      "-3.0125112792974833\n",
      "-2.8088846496717097\n",
      "-2.7989879957047195\n",
      "-2.697274250541595\n",
      "-2.610003713613706\n",
      "-2.4625334767972604\n",
      "-2.4737770708386493\n",
      "-2.3393201864076887\n",
      "-1.943005806174283\n",
      "-1.8845878586765525\n",
      "-1.585351930298599\n",
      "-1.3558993121712308\n",
      "8.665354182261469\n",
      "-4.390820527016216\n",
      "-4.8801186061537285\n",
      "-4.754962905444642\n",
      "-4.981757024298928\n",
      "-5.213599019660733\n",
      "-5.350290680410409\n",
      "-5.592356415418208\n",
      "-5.799911981540503\n",
      "-4.842153630126432\n",
      "-17.2860951918818\n",
      "-100\n",
      "-1.7447583995912226\n",
      "0.9150125971557099\n",
      "0.03540978006422507\n",
      "-1.6581149603442384\n",
      "-3.186138230275122\n",
      "-2.2350667537751745\n",
      "1.6218681301434412\n",
      "1.6442630211986125\n",
      "-1.0540705704578273\n",
      "1.8672793775294292\n",
      "1.923316474482989\n",
      "0.6508218276322009\n",
      "-0.611750374995313\n",
      "-2.865093893482583\n",
      "-1.530318382528178\n",
      "-1.2933719746282748\n",
      "0.2092995205396278\n",
      "0.6465611548581773\n",
      "-2.4601625593581558\n",
      "-0.8217651296022439\n",
      "-2.4265871273515414\n",
      "-0.7406106925370068\n",
      "0.5130742937355148\n",
      "-3.244269120320655\n",
      "-0.4229228474337276\n",
      "-1.241911892854563\n",
      "-1.0040701820962454\n",
      "-0.11508356848574408\n",
      "0.5439731592948089\n",
      "-1.5801718079715943\n",
      "0.14281708108859562\n",
      "0.6973424554151222\n",
      "-0.2456046022350506\n",
      "0.09112549538279496\n",
      "-0.09848355168098805\n",
      "-0.5671442400688307\n",
      "-1.9618024350565009\n",
      "0.48254542111431076\n",
      "-2.509858221684186\n",
      "-1.6875957498934782\n",
      "1.012609331748764\n",
      "1.19321125499181\n",
      "-3.6979132775323817\n",
      "1.3675897734791829\n",
      "0.20170301903051496\n",
      "2.4882994530972\n",
      "2.121479098376568\n",
      "1.4569297252713522\n",
      "1.1455251121536503\n",
      "0.46327301901215034\n",
      "2.55883377866071\n",
      "0.554019198864496\n",
      "0.4500765142785042\n",
      "-0.4384272119802574\n",
      "0.8532526233995281\n",
      "1.4029271729684296\n",
      "2.267101045001199\n",
      "-0.017671682281064693\n",
      "3.506950330786766\n",
      "-3.316213954338326\n",
      "-2.815089345552212\n",
      "3.7981650351017335\n",
      "-3.6826823720113735\n",
      "3.926611238769483\n",
      "3.9804169482445686\n",
      "4.110159323840635\n",
      "-0.8195077066805709\n",
      "4.446506373047499\n",
      "0.7346715434506847\n",
      "4.805314870738358\n",
      "-0.016058414428669038\n",
      "-2.5659330992485705\n",
      "-5.131446730701128\n",
      "-3.8566808116719913\n",
      "0.33838785162010937\n",
      "-3.1227853239538375\n",
      "-3.703949584291041\n",
      "-0.8897743587406512\n",
      "-3.0680998593585\n",
      "-2.086941410720584\n",
      "-2.157900229290361\n",
      "-2.5937239276971966\n",
      "-1.3543674758729651\n",
      "-3.2032398169992176\n",
      "-1.4768673738212386\n",
      "-2.0689890617841784\n",
      "-1.7232980218371836\n",
      "-2.1763339750098383\n",
      "-1.9832439048553454\n",
      "-1.2798096542022563\n",
      "-1.181774878497207\n",
      "-1.6761387700331045\n",
      "-1.9812075405358474\n",
      "-1.989508781385125\n",
      "-2.0189079266029055\n",
      "1.48546225967591\n",
      "-1.72407394626748\n",
      "0.5787740537468664\n",
      "-1.5047994444299764\n",
      "-0.030387100090723596\n",
      "-0.4561838213455928\n",
      "-0.9540029062490578\n",
      "0.2534421278478874\n",
      "-0.4495103385352081\n",
      "0.30770449747462864\n",
      "-0.7784938792271976\n",
      "-0.713745663993069\n",
      "0.6609684971273964\n",
      "-0.027360064030193587\n",
      "-0.3010039803065172\n",
      "-0.3616871202960954\n",
      "-1.4211523193644553\n",
      "-0.039442461878165885\n",
      "-0.14042794260850996\n",
      "1.2020474935291758\n",
      "0.0604142532758101\n",
      "2.308286278609512\n",
      "1.0617842736052523\n",
      "1.0063654375020417\n",
      "0.151728590975506\n",
      "0.9242002925635131\n",
      "1.7107362859042723\n",
      "1.0801505065795152\n",
      "1.2269377151936964\n",
      "1.0907554540377487\n",
      "2.121750945888505\n",
      "2.160227896815184\n",
      "1.371513739760826\n",
      "1.9873642263458293\n",
      "2.6885054792272856\n",
      "2.4576484050300964\n",
      "2.3844398318267124\n",
      "0.6543458615656845\n",
      "2.1845863374114187\n",
      "2.667733157626175\n",
      "-1.4325725724313998\n",
      "-1.7650979315029816\n",
      "-3.707293631337012\n",
      "-2.8450213185875723\n",
      "-0.41323974368380617\n",
      "-3.0169830406055267\n",
      "-1.5944129731100987\n",
      "-0.029629207942764413\n",
      "-1.7563773733378867\n",
      "-3.5007354702042788\n",
      "0.057036599147249956\n",
      "0.4249826712755976\n",
      "-2.2807937316175355\n",
      "-0.01620380825470419\n",
      "-2.2948711948786524\n",
      "-1.868995968151778\n",
      "-0.140426915583663\n",
      "-0.7581438845395667\n",
      "-1.7931290076777942\n",
      "-3.6401376636098335\n",
      "0.5059842304003552\n",
      "-3.339133483450864\n",
      "-3.58989630373233\n",
      "-0.20378528008125157\n",
      "1.7318859451998605\n",
      "-4.378913242790815\n",
      "-4.16931010035202\n",
      "-3.856271237822226\n",
      "-3.5673451113047734\n",
      "-3.2869416954217443\n",
      "-3.053345765016131\n",
      "-0.87355901910978\n",
      "0.525183348126103\n",
      "-2.4633647430481447\n",
      "-2.08912641016414\n",
      "-0.809974895136935\n",
      "-1.8518920153996123\n",
      "-1.2362948864078647\n",
      "-1.1334308752554978\n",
      "-0.9308026785704999\n",
      "-0.588206526642739\n",
      "-0.47508972942093236\n",
      "-0.4486846546032257\n",
      "0.32091001607703334\n",
      "-1.7576691572067376\n",
      "0.28172580933287006\n",
      "-0.5588294068570576\n",
      "0.2837936941591874\n",
      "-1.9417796855447478\n",
      "0.7282624034508853\n",
      "-0.8786023431701893\n",
      "0.6296779154911405\n",
      "1.3242058477871705\n",
      "1.1986272155596407\n",
      "0.9998267251585389\n",
      "1.5663569453148238\n",
      "0.054156536940593025\n",
      "2.029642938566725\n",
      "2.0363193232831818\n",
      "2.1547872065245897\n",
      "2.2742787142497902\n",
      "2.7746945481646335\n",
      "1.9551992632240285\n",
      "3.0781801115720966\n",
      "4.309438382220788\n",
      "3.961542874475936\n",
      "2.96203370734234\n",
      "4.345036793758692\n",
      "3.674146714374531\n",
      "3.9544513929276106\n",
      "4.779729215439613\n",
      "6.63313858972175\n",
      "3.898022276738574\n",
      "5.438123870850501\n",
      "3.482875981920029\n",
      "-1.1183254038791393\n",
      "-4.229194495693917\n",
      "-1.0419567895886417\n",
      "-2.2476316554321327\n",
      "-2.1876785459008827\n",
      "-2.043594081979921\n",
      "-3.0902312635110034\n",
      "-2.1524275361832563\n",
      "0.2744146525381666\n",
      "-4.680962069590236\n",
      "0.8004839300224205\n",
      "1.9347265983185877\n",
      "-3.4568254928256463\n",
      "-5.487863982188428\n",
      "-0.10396286329556687\n",
      "-2.3539096609495003\n",
      "0.6433679452525041\n",
      "-6.276923434120192\n",
      "-6.06969385726731\n",
      "-5.7279096544174015\n",
      "-5.389171203052142\n",
      "-5.061498190090872\n",
      "-4.76396424048903\n",
      "-2.0599164130344887\n",
      "-4.382922451965782\n",
      "-0.1403871306247197\n",
      "-4.329540467969962\n",
      "-3.843193097552272\n",
      "-3.66694327847125\n",
      "-3.179896332919013\n",
      "-0.08124331444871585\n",
      "-2.9929820045079496\n",
      "-2.5751659001048766\n",
      "-2.35232700613838\n",
      "-2.148775834433478\n",
      "-1.7190663865584372\n",
      "-1.534285492055999\n",
      "-1.1227705067904867\n",
      "-0.8070460735156348\n",
      "-0.6077914262578747\n",
      "0.5968832423773278\n",
      "0.27433442392959934\n",
      "-0.09087426767464876\n",
      "-0.04736030704898894\n",
      "-1.0022291482135188\n",
      "-0.22331733567783657\n",
      "0.3423482165780183\n",
      "0.9693751137405979\n",
      "0.9210568688218654\n",
      "1.3825889230224686\n",
      "1.690785373475877\n",
      "1.8022040592621533\n",
      "2.2817215647553737\n",
      "1.4641346697887456\n",
      "2.7306204861535277\n",
      "2.910462999653505\n",
      "1.2810598500762864\n",
      "2.303215308997051\n",
      "1.186170668239481\n",
      "2.9281685143912286\n",
      "3.252600262289407\n",
      "2.696436209686749\n",
      "2.8964360759731007\n",
      "12.938018126023083\n",
      "67.68856271728498\n",
      "-7.186569828847779\n",
      "-3.308919762763962\n",
      "-3.0364854475845946\n",
      "-2.794424628237407\n",
      "-2.83658477802649\n",
      "-2.5036733968823044\n",
      "-2.389035148788422\n",
      "-2.172143811853742\n",
      "-1.9620840569212123\n",
      "-2.1662306747662954\n",
      "-2.4564364566381003\n",
      "-2.800639087906261\n",
      "-2.8850002251828344\n",
      "-3.129291765181192\n",
      "-3.398478788147911\n",
      "-3.380871316128689\n",
      "-3.940749218231956\n",
      "-4.2668397659018344\n",
      "-4.453406020758705\n",
      "-14.56621269964168\n",
      "5.429560168259031\n",
      "-5.010785890031655\n",
      "-5.08504465545198\n",
      "-15.311170365677382\n",
      "4.660605216474864\n",
      "-5.666138176100076\n",
      "-5.962326067223471\n",
      "-100\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C # Advantage Actor Critic (A2C) algorithm\n",
    "\n",
    "env = gym.make('LunarLander-v2') \n",
    "env.reset()\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "for ep in range(episodes):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\twhile not done:\n",
    "\t\taction, _states = model.predict(obs)\n",
    "\t\tobs, rewards, done, info = env.step(action)\n",
    "\t\tenv.render()\n",
    "\t\tprint(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 89.9     |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    fps             | 2403     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.3        |\n",
      "|    ep_rew_mean          | -201        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013141309 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00459    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 627         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.1        |\n",
      "|    ep_rew_mean          | -188        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007094233 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0069     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 672         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.8        |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008495745 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.00336    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 465         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    value_loss           | 947         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.2        |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1520        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011164795 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 634         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.9        |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009803246 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.0136     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    value_loss           | 831         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1472        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008694139 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.000315    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 441         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 113         |\n",
      "|    ep_rew_mean          | -129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1455        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009802516 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 416         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -122        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007824207 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.00162    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 130         |\n",
      "|    ep_rew_mean          | -124        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1430        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009865434 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.00445     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 457         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 138          |\n",
      "|    ep_rew_mean          | -117         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1420         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075219264 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 187          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 381          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 148          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047280327 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.0913       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    value_loss           | 475          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016099859 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 172        |\n",
      "|    ep_rew_mean          | -107       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1367       |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892552 |\n",
      "|    clip_fraction        | 0.0544     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 68.6       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0058    |\n",
      "|    value_loss           | 209        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1325        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004494732 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.1        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008929482 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 212         |\n",
      "|    ep_rew_mean          | -95.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118998 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 226         |\n",
      "|    ep_rew_mean          | -95.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1243        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011971191 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 236          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1228         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077221775 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 244          |\n",
      "|    ep_rew_mean          | -93.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1223         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044020084 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 256         |\n",
      "|    ep_rew_mean          | -91.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1175        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944144 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | -81.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1161        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032410413 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | -74.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1147        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010455906 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 308         |\n",
      "|    ep_rew_mean          | -76.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1130        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011423139 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m PPO(\u001b[39m'\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m'\u001b[39m, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m100000\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m episodes \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(episodes):\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:307\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    298\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    299\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    305\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    308\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    309\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    310\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    311\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    312\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    313\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    314\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:248\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    244\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    246\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 248\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:166\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     obs_tensor \u001b[39m=\u001b[39m obs_as_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 166\u001b[0m     actions, values, log_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(obs_tensor)\n\u001b[0;32m    167\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    169\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\policies.py:634\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[0;32m    633\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_net(latent_vf)\n\u001b[1;32m--> 634\u001b[0m distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent_pi)\n\u001b[0;32m    635\u001b[0m actions \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[0;32m    636\u001b[0m log_prob \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\policies.py:667\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(mean_actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_std)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    666\u001b[0m     \u001b[39m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dist\u001b[39m.\u001b[39;49mproba_distribution(action_logits\u001b[39m=\u001b[39;49mmean_actions)\n\u001b[0;32m    668\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, MultiCategoricalDistribution):\n\u001b[0;32m    669\u001b[0m     \u001b[39m# Here mean_actions are the flattened logits\u001b[39;00m\n\u001b[0;32m    670\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\common\\distributions.py:288\u001b[0m, in \u001b[0;36mCategoricalDistribution.proba_distribution\u001b[1;34m(self, action_logits)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mproba_distribution\u001b[39m(\u001b[39mself\u001b[39m: SelfCategoricalDistribution, action_logits: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfCategoricalDistribution:\n\u001b[1;32m--> 288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m Categorical(logits\u001b[39m=\u001b[39;49maction_logits)\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\h4rip\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\distributions\\categorical.py:62\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`logits` parameter must be at least one-dimensional.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[39m# Normalize\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits \u001b[39m=\u001b[39m logits \u001b[39m-\u001b[39m logits\u001b[39m.\u001b[39;49mlogsumexp(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobs \u001b[39mif\u001b[39;00m probs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits\n\u001b[0;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_events \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO # Proximal Policy Optimization (PPO)\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "for ep in range(episodes):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\twhile not done:\n",
    "\t\taction, _states = model.predict(obs)\n",
    "\t\tobs, rewards, done, info = env.step(action)\n",
    "\t\tenv.render()\n",
    "\t\tprint(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbc59299d2ef61f825f02686d0901dc51aae6fa14013db0a976e69a0c7bf9ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
